{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "187faf2e-4e39-461a-9dce-1882ee82719f",
   "metadata": {},
   "source": [
    "This notebook provides template functions to initialize a DuckDB database from default and split CSV files. Subsequent data analysis in Ibis can proceed agnostic to the underlying format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "456c2ec7-1384-40c1-b131-29a7ba74f20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_ddb_from_csv(db_filename, tablename, csv_filename, **kwargs):\n",
    "    \"\"\"\n",
    "    Load from the csv file into a DuckDB database.\n",
    "    \n",
    "    db_filename: Name of the database\n",
    "    tablename: Table to load to\n",
    "    csv_filename: CSV file to load from\n",
    "    **kwargs: Options for DuckDB's read_csv function, see https://duckdb.org/docs/data/csv/overview\n",
    "    \"\"\"\n",
    "    import duckdb\n",
    "    duckdb_con = duckdb.connect(db_filename)\n",
    "    read_csv_args_list = [\"'{}'\".format(csv_filename)]\n",
    "    for key, value in kwargs.items():\n",
    "        read_csv_args_list.append(\"{0} = {1}\".format(key, value))\n",
    "    read_csv_args = ','.join(read_csv_args_list)\n",
    "    sql_stmt = \"CREATE TABLE {} AS SELECT * FROM read_csv({}, AUTO_DETECT=TRUE)\".format(tablename, read_csv_args)\n",
    "    print(sql_stmt)\n",
    "    duckdb_con.sql(sql_stmt)\n",
    "    duckdb_con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89516588-2833-4abf-b79f-764df70e55c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_ddb_from_split_csv(db_filename, tablename, split_csv_foldername, **kwargs):\n",
    "    \"\"\"\n",
    "    Load the split csv file into a DuckDB database and expose a view with tablename\n",
    "\n",
    "    db_filename: Name of the database\n",
    "    tablename: View to expose giving the impression of a table\n",
    "    csv_filename: Folder containing the split CSV files\n",
    "    **kwargs: Options for DuckDB's read_csv function, see https://duckdb.org/docs/data/csv/overview\n",
    "    \"\"\"\n",
    "    import duckdb\n",
    "    import os\n",
    "    duckdb_con = duckdb.connect(db_filename)\n",
    "    # read_csv_args_list = [\"'{}'\".format(csv_filename)]\n",
    "    # for key, value in kwargs.items():\n",
    "    #     read_csv_args_list.append(\"{0} = {1}\".format(key, value))\n",
    "    # read_csv_args = ','.join(read_csv_args_list)\n",
    "    num_dims = 0\n",
    "    cols = []\n",
    "    sub_tablenames = []\n",
    "    for root, dirs, files in os.walk(split_csv_foldername):\n",
    "        for file in files:\n",
    "            if 'dim' in file:\n",
    "                num_dims += 1\n",
    "            sub_tablename = tablename + \"_\" + file.split(\".csv\")[0]\n",
    "            sub_tablenames.append(sub_tablename)\n",
    "            full_filename = root + '/' + file\n",
    "            sql_stmt = \"CREATE TABLE {} AS SELECT * FROM read_csv('{}', AUTO_DETECT=TRUE)\".format(sub_tablename, full_filename)\n",
    "            print(sql_stmt)\n",
    "            duckdb_con.sql(sql_stmt)\n",
    "            table = duckdb_con.table(sub_tablename)\n",
    "            for col in table.columns:\n",
    "                # HACK: not fool proof, the CSV could contain a column starting with letter 'p'\n",
    "                if col[0] == 'p':\n",
    "                    continue\n",
    "                cols.append('\"' + col + '\"')\n",
    "\n",
    "    # Now create a view corresponding to a single original csv file\n",
    "    join_clauses = []\n",
    "    for i in range(num_dims):\n",
    "        join_clause = \"{}_fact.p{} = {}_dim{}.p{}\".format(tablename, i, tablename, i, i)\n",
    "        join_clauses.append(join_clause)\n",
    "\n",
    "    sql_stmt = \"CREATE VIEW {} AS SELECT \".format(tablename) + \",\".join(cols) + \\\n",
    "        \" FROM \" + \",\".join(sub_tablenames) + \" WHERE \" + (\" AND \").join(join_clauses)\n",
    "    print(sql_stmt)\n",
    "    duckdb_con.sql(sql_stmt)\n",
    "    duckdb_con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b149e726-58a8-4364-a85f-482f0230a2fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE TABLE accidents AS SELECT * FROM read_csv('us-accidents/default/US_Accidents_Dec21_updated.csv', AUTO_DETECT=TRUE)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a2951c89dca429cb63e6e87f0a1c17c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "init_ddb_from_csv(\"us-accidents/default/us_accidents_default.db\", \"accidents\", \"us-accidents/default/US_Accidents_Dec21_updated.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d9b1867-b8e1-43e4-bb6d-1e833e62f529",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm us-accidents/default/us_accidents_default.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de528a2c-e558-4d64-9964-5e98e07707ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE TABLE accidents_dim8 AS SELECT * FROM read_csv('us-accidents/split/US_Accidents_Dec21_updated/dim8.csv', AUTO_DETECT=TRUE)\n"
     ]
    },
    {
     "ename": "CatalogException",
     "evalue": "Catalog Error: Table with name \"accidents_dim8\" already exists!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCatalogException\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43minit_ddb_from_split_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mus-accidents/split/us_accidents_split.db\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maccidents\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mus-accidents/split/US_Accidents_Dec21_updated\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \n",
      "Cell \u001b[0;32mIn[8], line 29\u001b[0m, in \u001b[0;36minit_ddb_from_split_csv\u001b[0;34m(db_filename, tablename, split_csv_foldername, **kwargs)\u001b[0m\n\u001b[1;32m     27\u001b[0m sql_stmt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCREATE TABLE \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m AS SELECT * FROM read_csv(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, AUTO_DETECT=TRUE)\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(sub_tablename, full_filename)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(sql_stmt)\n\u001b[0;32m---> 29\u001b[0m \u001b[43mduckdb_con\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql_stmt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m table \u001b[38;5;241m=\u001b[39m duckdb_con\u001b[38;5;241m.\u001b[39mtable(sub_tablename)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m table\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;66;03m# HACK: not fool proof, the CSV could contain a column starting with letter 'p'\u001b[39;00m\n",
      "\u001b[0;31mCatalogException\u001b[0m: Catalog Error: Table with name \"accidents_dim8\" already exists!"
     ]
    }
   ],
   "source": [
    "init_ddb_from_split_csv(\"us-accidents/split/us_accidents_split.db\", \"accidents\", \"us-accidents/split/US_Accidents_Dec21_updated\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6faccaa8-cb3a-43f2-af78-dfbe2ca95014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'us-accidents/split/us_accidents_split.db': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!rm us-accidents/split/us_accidents_split.db*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2afb0558-4a27-4914-b234-8c65f2749c63",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/code/shrutimehta/analysis-of-nyc-parking-tickets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6afd9ec-8cbc-4f0e-a603-ceea0b98e416",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_ddb_from_csv(db_filename, tablename, csv_filename, **kwargs):\n",
    "    \"\"\"\n",
    "    Load from the csv file into a DuckDB database.\n",
    "    \n",
    "    db_filename: Name of the database\n",
    "    tablename: Table to load to\n",
    "    csv_filename: CSV file to load from\n",
    "    **kwargs: Options for DuckDB's read_csv function, see https://duckdb.org/docs/data/csv/overview\n",
    "    \"\"\"\n",
    "    import duckdb\n",
    "    duckdb_con = duckdb.connect(db_filename)\n",
    "    read_csv_args_list = [\"'{}'\".format(csv_filename)]\n",
    "    schema = {tablename : {\n",
    "        \"fact\" : tablename + \"_fact\",\n",
    "        \"dimension_tables\" : {},\n",
    "        \"col_to_table_map\" : {}\n",
    "    }}\n",
    "    for key, value in kwargs.items():\n",
    "        read_csv_args_list.append(\"{0} = {1}\".format(key, value))\n",
    "    read_csv_args = ','.join(read_csv_args_list)\n",
    "    sql_stmt = \"CREATE TABLE {} AS SELECT * FROM read_csv({}, AUTO_DETECT=TRUE)\".format(tablename, read_csv_args)\n",
    "    print(sql_stmt)\n",
    "    duckdb_con.sql(sql_stmt)\n",
    "    table = duckdb_con.table(tablename)\n",
    "    for col in table.columns:\n",
    "        schema[tablename][\"col_to_table_map\"][col] = schema[tablename][\"fact\"]\n",
    "    duckdb_con.close()\n",
    "    return schema\n",
    "\n",
    "def init_ddb_from_split_csv(db_filename, tablename, split_csv_foldername, **kwargs):\n",
    "    \"\"\"\n",
    "    Load the split csv file into a DuckDB database and expose a view with tablename\n",
    "\n",
    "    db_filename: Name of the database\n",
    "    tablename: View to expose giving the impression of a table\n",
    "    csv_filename: Folder containing the split CSV files\n",
    "    **kwargs: Options for DuckDB's read_csv function, see https://duckdb.org/docs/data/csv/overview\n",
    "    \"\"\"\n",
    "    import duckdb\n",
    "    import os\n",
    "    duckdb_con = duckdb.connect(db_filename)\n",
    "    schema = {tablename : {\n",
    "        \"fact\" : tablename + \"_fact\",\n",
    "        \"dimension_tables\" : {},\n",
    "        \"col_to_table_map\" : {}\n",
    "    }}\n",
    "    read_csv_args_list = [\"AUTO_DETECT = TRUE\"]\n",
    "    for key, value in kwargs.items():\n",
    "        read_csv_args_list.append(\"{0} = {1}\".format(key, value))\n",
    "    read_csv_args = ','.join(read_csv_args_list)\n",
    "    num_dims = 0\n",
    "    cols = []\n",
    "    sub_tablenames = []\n",
    "    for root, dirs, files in os.walk(split_csv_foldername):\n",
    "        for file in files:\n",
    "            sub_tablename = tablename + \"_\" + file.split(\".csv\")[0]\n",
    "            sub_tablenames.append(sub_tablename)\n",
    "            if 'dim' in file:\n",
    "                num_dims += 1\n",
    "                # Assuming that dimension tables are named dimx.csv\n",
    "                dim_no = sub_tablename.split(\"dim\")[1]\n",
    "                schema[tablename][\"dimension_tables\"][sub_tablename] = 'p' + dim_no\n",
    "            full_filename = root + '/' + file\n",
    "            sql_stmt = \"CREATE TABLE {} AS SELECT * FROM read_csv('{}', {})\".format(sub_tablename, full_filename, read_csv_args)\n",
    "            print(sql_stmt)\n",
    "            duckdb_con.sql(sql_stmt)\n",
    "            table = duckdb_con.table(sub_tablename)\n",
    "            for col in table.columns:\n",
    "                # HACK: not fool proof, the CSV could contain a column starting with letter 'p'\n",
    "                if col[0] == 'p':\n",
    "                    continue\n",
    "                cols.append('\"' + col + '\"')\n",
    "                schema[tablename]['col_to_table_map'][col] = sub_tablename\n",
    "\n",
    "    # Now create a view corresponding to a single original csv file\n",
    "    join_clauses = []\n",
    "    for i in range(num_dims):\n",
    "        join_clause = \"{}_fact.p{} = {}_dim{}.p{}\".format(tablename, i, tablename, i, i)\n",
    "        join_clauses.append(join_clause)\n",
    "\n",
    "    sql_stmt = \"CREATE VIEW {} AS SELECT \".format(tablename) + \",\".join(cols) + \\\n",
    "        \" FROM \" + \",\".join(sub_tablenames) + \" WHERE \" + (\" AND \").join(join_clauses)\n",
    "    print(sql_stmt)\n",
    "    duckdb_con.sql(sql_stmt)\n",
    "    duckdb_con.close()\n",
    "    return schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c69f5e8-d55e-4b0c-9044-99f32b443a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Default format\n",
    "# tablename = \"tickets_2014\"\n",
    "# input_file = \"nyc_parking_tickets/Parking_Violations_Issued_-_Fiscal_Year_2014__August_2013___June_2014_.csv\"\n",
    "# schema1 = init_ddb_from_csv(dbname, tablename, input_file, ALL_VARCHAR=True)\n",
    "\n",
    "# tablename = \"tickets_2015\"\n",
    "# input_file = \"nyc_parking_tickets/Parking_Violations_Issued_-_Fiscal_Year_2015.csv\"\n",
    "# schema2 = init_ddb_from_csv(dbname, tablename, input_file, ALL_VARCHAR=True)\n",
    "\n",
    "# tablename = \"tickets_2016\"\n",
    "# input_file = \"nyc_parking_tickets/Parking_Violations_Issued_-_Fiscal_Year_2016.csv\"\n",
    "# schema3 = init_ddb_from_csv(dbname, tablename, input_file, ALL_VARCHAR=True)\n",
    "\n",
    "# tablename = \"tickets_2017\"\n",
    "# input_file = \"nyc_parking_tickets/Parking_Violations_Issued_-_Fiscal_Year_2017.csv\"\n",
    "# schema4 = init_ddb_from_csv(dbname, tablename, input_file, ALL_VARCHAR=True)\n",
    "\n",
    "# # Split format\n",
    "# tablename = \"tickets_2014\"\n",
    "# input_file = \"nyc_parking_tickets_split/Parking_Violations_Issued_-_Fiscal_Year_2014__August_2013___June_2014_\"\n",
    "# schema1 = init_ddb_from_split_csv(dbname, tablename, input_file, SAMPLE_SIZE=-1)\n",
    "\n",
    "# tablename = \"tickets_2015\"\n",
    "# input_file = \"nyc_parking_tickets_split/Parking_Violations_Issued_-_Fiscal_Year_2015\"\n",
    "# schema2 = init_ddb_from_split_csv(dbname, tablename, input_file, SAMPLE_SIZE=-1)\n",
    "\n",
    "# tablename = \"tickets_2016\"\n",
    "# input_file = \"nyc_parking_tickets_split/Parking_Violations_Issued_-_Fiscal_Year_2016\"\n",
    "# schema3 = init_ddb_from_split_csv(dbname, tablename, input_file, SAMPLE_SIZE=-1)\n",
    "\n",
    "# tablename = \"tickets_2017\"\n",
    "# input_file = \"nyc_parking_tickets_split/Parking_Violations_Issued_-_Fiscal_Year_2017\"\n",
    "# schema4 = init_ddb_from_split_csv(dbname, tablename, input_file, SAMPLE_SIZE=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9014f3-abac-4e84-ac34-78b5d0318d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbname = \"nyc_parking_tickets.db\"\n",
    "\n",
    "# # Default format\n",
    "# tablename = \"tickets_2014\"\n",
    "# input_file = \"nyc_parking_tickets/Parking_Violations_Issued_-_Fiscal_Year_2014__August_2013___June_2014_.csv\"\n",
    "# schema1 = init_ddb_from_csv(dbname, tablename, input_file, ALL_VARCHAR=True)\n",
    "\n",
    "# tablename = \"tickets_2015\"\n",
    "# input_file = \"nyc_parking_tickets/Parking_Violations_Issued_-_Fiscal_Year_2015.csv\"\n",
    "# schema2 = init_ddb_from_csv(dbname, tablename, input_file, ALL_VARCHAR=True)\n",
    "\n",
    "# tablename = \"tickets_2016\"\n",
    "# input_file = \"nyc_parking_tickets/Parking_Violations_Issued_-_Fiscal_Year_2016.csv\"\n",
    "# schema3 = init_ddb_from_csv(dbname, tablename, input_file, ALL_VARCHAR=True)\n",
    "\n",
    "# tablename = \"tickets_2017\"\n",
    "# input_file = \"nyc_parking_tickets/Parking_Violations_Issued_-_Fiscal_Year_2017.csv\"\n",
    "# schema4 = init_ddb_from_csv(dbname, tablename, input_file, ALL_VARCHAR=True)\n",
    "\n",
    "# Split format\n",
    "tablename = \"tickets_2014\"\n",
    "input_file = \"nyc_parking_tickets_split/Parking_Violations_Issued_-_Fiscal_Year_2014__August_2013___June_2014_\"\n",
    "schema1 = init_ddb_from_split_csv(dbname, tablename, input_file, SAMPLE_SIZE=-1)\n",
    "\n",
    "tablename = \"tickets_2015\"\n",
    "input_file = \"nyc_parking_tickets_split/Parking_Violations_Issued_-_Fiscal_Year_2015\"\n",
    "schema2 = init_ddb_from_split_csv(dbname, tablename, input_file, SAMPLE_SIZE=-1)\n",
    "\n",
    "tablename = \"tickets_2016\"\n",
    "input_file = \"nyc_parking_tickets_split/Parking_Violations_Issued_-_Fiscal_Year_2016\"\n",
    "schema3 = init_ddb_from_split_csv(dbname, tablename, input_file, SAMPLE_SIZE=-1)\n",
    "\n",
    "tablename = \"tickets_2017\"\n",
    "input_file = \"nyc_parking_tickets_split/Parking_Violations_Issued_-_Fiscal_Year_2017\"\n",
    "schema4 = init_ddb_from_split_csv(dbname, tablename, input_file, SAMPLE_SIZE=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05369033-dece-450e-96c0-2161c5a1c2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ibis\n",
    "import os\n",
    "\n",
    "# Since we want all expressions to run, even if the output is not used\n",
    "# By default, expressions are lazily evaluated\n",
    "# The function call to_pandas() explicitly evaluates an expression\n",
    "# We want to avoid invoking to_pandas() all the time\n",
    "ibis.options.interactive = True\n",
    "\n",
    "con = ibis.duckdb.connect(dbname)\n",
    "for schema in [schema1, schema2, schema3, schema4]:\n",
    "    con.register_schema(schema)\n",
    "con.tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa114f3-0573-4dc5-a4fe-65fe30b129ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickets_2014 = con.table('tickets_2014')\n",
    "tickets_2014.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5444c93-9dd8-4857-834d-cbe04cc4b7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_by_state = tickets_2014.group_by('Registration State').aggregate(tickets_2014.count())\n",
    "count_by_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65559f5a-d739-4c6f-b9e3-9510c95d3907",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_by_state.filter(count_by_state['Registration State'] == 'NY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7e0fa5-9ae5-4632-9802-5db8ef14422e",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_by_state = count_by_state.filter(count_by_state['Registration State'] != '99')\n",
    "count_by_state.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56383eac-2580-46c9-b583-1842ef1a7c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_by_state_exclude_ny = count_by_state.filter(count_by_state['Registration State'] != 'NY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05ccad8-a304-481e-8df5-c65d3ca5ced8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickets_2014.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0e7b4f-9cc2-40f1-b8da-bceea9a3ddc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickets_nyc = tickets_2014[tickets_2014['Registration State'] == 'NY']\n",
    "tickets_nyc = tickets_nyc.mutate(month=tickets_nyc['Issue Date'].month())\n",
    "\n",
    "month_grp_nyc = tickets_nyc.group_by(tickets_nyc.month).aggregate(tickets_nyc.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f93766e-af78-4981-91a2-c62c96b9e4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "month_grp_nyc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e8319a-db4a-47f9-bf1c-6ddaa2da25c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickets_other_cities = tickets_2014[tickets_2014['Registration State'] != 'NY']\n",
    "tickets_other_cities = tickets_other_cities.mutate(month=tickets_other_cities['Issue Date'].month())\n",
    "\n",
    "month_grp_other_cities = tickets_other_cities.group_by(tickets_other_cities.month).aggregate(tickets_other_cities.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2f473b-7d96-4e18-a5b0-0767e4670f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "month_grp_other_cities.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d501592-4fc0-47c9-91fd-d66c7bf91f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm $dbname*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

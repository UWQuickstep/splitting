{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "729f4c30-2941-4e08-9651-c06aa52ca58a",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/code/argha48/preliminary-data-visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16cd69d8-4328-4c4f-868b-bc3185502337",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_ddb_from_csv(db_filename, tablename, csv_filename, **kwargs):\n",
    "    \"\"\"\n",
    "    Load from the csv file into a DuckDB database.\n",
    "    \n",
    "    db_filename: Name of the database\n",
    "    tablename: Table to load to\n",
    "    csv_filename: CSV file to load from\n",
    "    **kwargs: Options for DuckDB's read_csv function, see https://duckdb.org/docs/data/csv/overview\n",
    "    \"\"\"\n",
    "    import duckdb\n",
    "    duckdb_con = duckdb.connect(db_filename)\n",
    "    read_csv_args_list = [\"'{}'\".format(csv_filename)]\n",
    "    schema = {tablename : {\n",
    "        \"fact\" : tablename + \"_fact\",\n",
    "        \"dimension_tables\" : {},\n",
    "        \"col_to_table_map\" : {}\n",
    "    }}\n",
    "    for key, value in kwargs.items():\n",
    "        read_csv_args_list.append(\"{0} = {1}\".format(key, value))\n",
    "    read_csv_args = ','.join(read_csv_args_list)\n",
    "    sql_stmt = \"CREATE TABLE {} AS SELECT * FROM read_csv({}, AUTO_DETECT=TRUE)\".format(tablename, read_csv_args)\n",
    "    print(sql_stmt)\n",
    "    duckdb_con.sql(sql_stmt)\n",
    "    table = duckdb_con.table(tablename)\n",
    "    for col in table.columns:\n",
    "        schema[tablename][\"col_to_table_map\"][col] = schema[tablename][\"fact\"]\n",
    "    duckdb_con.close()\n",
    "    return schema\n",
    "\n",
    "def init_ddb_from_split_csv(db_filename, tablename, split_csv_foldername, **kwargs):\n",
    "    \"\"\"\n",
    "    Load the split csv file into a DuckDB database and expose a view with tablename\n",
    "\n",
    "    db_filename: Name of the database\n",
    "    tablename: View to expose giving the impression of a table\n",
    "    csv_filename: Folder containing the split CSV files\n",
    "    **kwargs: Options for DuckDB's read_csv function, see https://duckdb.org/docs/data/csv/overview\n",
    "    \"\"\"\n",
    "    import duckdb\n",
    "    import os\n",
    "    duckdb_con = duckdb.connect(db_filename)\n",
    "    schema = {tablename : {\n",
    "        \"fact\" : tablename + \"_fact\",\n",
    "        \"dimension_tables\" : {},\n",
    "        \"col_to_table_map\" : {}\n",
    "    }}\n",
    "    read_csv_args_list = [\"AUTO_DETECT = TRUE\"]\n",
    "    for key, value in kwargs.items():\n",
    "        read_csv_args_list.append(\"{0} = {1}\".format(key, value))\n",
    "    read_csv_args = ','.join(read_csv_args_list)\n",
    "    num_dims = 0\n",
    "    cols = []\n",
    "    sub_tablenames = []\n",
    "    for root, dirs, files in os.walk(split_csv_foldername):\n",
    "        for file in files:\n",
    "            sub_tablename = tablename + \"_\" + file.split(\".csv\")[0]\n",
    "            sub_tablenames.append(sub_tablename)\n",
    "            if 'dim' in file:\n",
    "                num_dims += 1\n",
    "                # Assuming that dimension tables are named dimx.csv\n",
    "                dim_no = sub_tablename.split(\"dim\")[1]\n",
    "                schema[tablename][\"dimension_tables\"][sub_tablename] = 'p' + dim_no\n",
    "            full_filename = root + '/' + file\n",
    "            sql_stmt = \"CREATE TABLE {} AS SELECT * FROM read_csv('{}', {})\".format(sub_tablename, full_filename, read_csv_args)\n",
    "            print(sql_stmt)\n",
    "            duckdb_con.sql(sql_stmt)\n",
    "            table = duckdb_con.table(sub_tablename)\n",
    "            for col in table.columns:\n",
    "                # HACK: not fool proof, the CSV could contain a column starting with letter 'p'\n",
    "                if col[0] == 'p':\n",
    "                    continue\n",
    "                cols.append('\"' + col + '\"')\n",
    "                schema[tablename]['col_to_table_map'][col] = sub_tablename\n",
    "\n",
    "    # Now create a view corresponding to a single original csv file\n",
    "    join_clauses = []\n",
    "    for i in range(num_dims):\n",
    "        join_clause = \"{}_fact.p{} = {}_dim{}.p{}\".format(tablename, i, tablename, i, i)\n",
    "        join_clauses.append(join_clause)\n",
    "\n",
    "    sql_stmt = \"CREATE VIEW {} AS SELECT \".format(tablename) + \",\".join(cols) + \\\n",
    "        \" FROM \" + \",\".join(sub_tablenames) + \" WHERE \" + (\" AND \").join(join_clauses)\n",
    "    print(sql_stmt)\n",
    "    duckdb_con.sql(sql_stmt)\n",
    "    duckdb_con.close()\n",
    "    return schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9168e98b-ae69-4d21-85c3-c7e3d167d903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE TABLE tickets_2014 AS SELECT * FROM read_csv('nyc_parking_tickets/Parking_Violations_Issued_-_Fiscal_Year_2014__August_2013___June_2014_.csv',SAMPLE_SIZE = -1, AUTO_DETECT=TRUE)\n"
     ]
    },
    {
     "ename": "IOException",
     "evalue": "IO Error: No files found that match the pattern \"nyc_parking_tickets/Parking_Violations_Issued_-_Fiscal_Year_2014__August_2013___June_2014_.csv\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOException\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m tablename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtickets_2014\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m input_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnyc_parking_tickets/Parking_Violations_Issued_-_Fiscal_Year_2014__August_2013___June_2014_.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 6\u001b[0m schema \u001b[38;5;241m=\u001b[39m \u001b[43minit_ddb_from_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdbname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtablename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSAMPLE_SIZE\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# # Split format\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# tablename = \"tickets_2014\"\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# input_file = \"nyc_parking_tickets_split/Parking_Violations_Issued_-_Fiscal_Year_2014__August_2013___June_2014_\"\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# schema = init_ddb_from_split_csv(dbname, tablename, input_file, SAMPLE_SIZE=-1)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[3], line 23\u001b[0m, in \u001b[0;36minit_ddb_from_csv\u001b[0;34m(db_filename, tablename, csv_filename, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m sql_stmt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCREATE TABLE \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m AS SELECT * FROM read_csv(\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, AUTO_DETECT=TRUE)\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(tablename, read_csv_args)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(sql_stmt)\n\u001b[0;32m---> 23\u001b[0m \u001b[43mduckdb_con\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql_stmt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m table \u001b[38;5;241m=\u001b[39m duckdb_con\u001b[38;5;241m.\u001b[39mtable(tablename)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m table\u001b[38;5;241m.\u001b[39mcolumns:\n",
      "\u001b[0;31mIOException\u001b[0m: IO Error: No files found that match the pattern \"nyc_parking_tickets/Parking_Violations_Issued_-_Fiscal_Year_2014__August_2013___June_2014_.csv\""
     ]
    }
   ],
   "source": [
    "dbname = \"nyc_parking_tickets.db\"\n",
    "\n",
    "# # Default format\n",
    "tablename = \"tickets_2014\"\n",
    "input_file = \"nyc_parking_tickets/Parking_Violations_Issued_-_Fiscal_Year_2014__August_2013___June_2014_.csv\"\n",
    "schema = init_ddb_from_csv(dbname, tablename, input_file, SAMPLE_SIZE=-1)\n",
    "\n",
    "# # Split format\n",
    "# tablename = \"tickets_2014\"\n",
    "# input_file = \"nyc_parking_tickets_split/Parking_Violations_Issued_-_Fiscal_Year_2014__August_2013___June_2014_\"\n",
    "# schema = init_ddb_from_split_csv(dbname, tablename, input_file, SAMPLE_SIZE=-1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
